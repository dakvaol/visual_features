{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "#import tempfile\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import MiniBatchSparsePCA\n",
    "from sklearn.cluster import KMeans\n",
    "from skimage.filters.rank import entropy\n",
    "from skimage.morphology import disk\n",
    "from PIL import Image, ImageStat\n",
    "#from skimage import img_as_float\n",
    "import pandas as pd\n",
    "#from multiprocessing import Process\n",
    "import matplotlib.image as img\n",
    "from scipy.cluster.vq import whiten\n",
    "from scipy.cluster.vq import kmeans\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as img\n",
    "import statistics\n",
    "from scipy import spatial\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Imported datasets </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ratings = pd.read_csv('./ml-20m/ratings.csv')\n",
    "#movie_list = pd.read_csv('movie_assets_sampled.csv')\n",
    "\n",
    "# In case I do not have time to run the program\n",
    "# The outputted features have been added to a CSV file \n",
    "#movie_df = pd.read_csv('output.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Visual features </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates brightness by splitting HSV color space into \n",
    "# hue, saturation, and value. The value is synonymous with brightness.\n",
    "def get_brightness(img):\n",
    "    image = img.copy()\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    #cv2.imshow('Image', hsv)\n",
    "    _, _, v = cv2.split(hsv)\n",
    "    sum = np.sum(v, dtype=np.float32)\n",
    "    num_of_pixels = v.shape[0] * v.shape[1]\n",
    "    return (sum * 100.0) / (num_of_pixels * 255.0)\n",
    "\n",
    "# Calculates saturation by splitting HSV color space into \n",
    "# hue, saturation, and value. Saturation is extracted and represents\n",
    "# saturation\n",
    "def get_saturation(img):\n",
    "    image = img.copy()\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    #cv2.imshow('Image', hsv)\n",
    "    _, s, _ = cv2.split(hsv)\n",
    "    sum = np.sum(s, dtype = np.float32)\n",
    "    num_of_pixels = s.shape[0] * s.shape[1]\n",
    "    return (sum * 100.0) / (num_of_pixels * 255.0)\n",
    "\n",
    "# Calculates entropy\n",
    "def get_entropy(img):\n",
    "    image = img.copy()\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    entropy_img = entropy(gray,disk(5))\n",
    "    all_sum = np.sum(entropy_img, dtype = np.float32)\n",
    "    num_of_pixels = entropy_img.shape[0] * entropy_img.shape[1]\n",
    "    return all_sum / num_of_pixels\n",
    "\n",
    "# Calculates image sharpness by the variance of the Laplacian\n",
    "def get_sharpness(img):\n",
    "    image = img.copy()\n",
    "    img2gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    return cv2.Laplacian(img2gray, cv2.CV_64F).var()\n",
    "\n",
    "# Return contrast (RMS contrast)\n",
    "def get_contrast(img):\n",
    "    image = img.copy()\n",
    "    img_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    return img_gray.std()\n",
    "\n",
    "\n",
    "def get_colorfulness(img):\n",
    "    image = img.copy()\n",
    "    # split the image into its respective RGB components\n",
    "    (B, G, R) = cv2.split(image.astype(\"float\"))\n",
    "    # compute rg = R - G\n",
    "    rg = np.absolute(R - G)\n",
    "    # compute yb = 0.5 * (R + G) - B\n",
    "    yb = np.absolute(0.5 * (R + G) - B)\n",
    "    # compute the mean and standard deviation of both `rg` and `yb`\n",
    "    (rbMean, rbStd) = (np.mean(rg), np.std(rg))\n",
    "    (ybMean, ybStd) = (np.mean(yb), np.std(yb))\n",
    "    # combine the mean and standard deviations\n",
    "    stdRoot = np.sqrt((rbStd ** 2) + (ybStd ** 2))\n",
    "    meanRoot = np.sqrt((rbMean ** 2) + (ybMean ** 2))\n",
    "    # derive the \"saturation\" metric and return it\n",
    "    return stdRoot + (0.3 * meanRoot)\n",
    "\n",
    "def get_dominant_color(img):\n",
    "    image = img.copy()\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    " \n",
    "    r = []\n",
    "    g = []\n",
    "    b = []\n",
    "    for row in image:\n",
    "        for temp_r, temp_g, temp_b in row:\n",
    "            r.append(temp_r)\n",
    "            g.append(temp_g)\n",
    "            b.append(temp_b)\n",
    "    \n",
    "    image_df = pd.DataFrame({'red' : r,\n",
    "                            'green' : g,\n",
    "                            'blue' : b})\n",
    "    \n",
    "    image_df['scaled_color_red'] = whiten(image_df['red'])\n",
    "    image_df['scaled_color_blue'] = whiten(image_df['blue'])\n",
    "    image_df['scaled_color_green'] = whiten(image_df['green'])\n",
    "    \n",
    "    cluster_centers, _ = kmeans(image_df[['scaled_color_red',\n",
    "                                        'scaled_color_blue',\n",
    "                                        'scaled_color_green']], 3)\n",
    "    \n",
    "    dominant_colors = []\n",
    "    \n",
    "    red_std, green_std, blue_std = image_df[['red',\n",
    "                                            'green',\n",
    "                                            'blue']].std()\n",
    "    \n",
    "    for cluster_center in cluster_centers:\n",
    "        red_scaled, green_scaled, blue_scaled = cluster_center\n",
    "        dominant_colors.append((\n",
    "            red_scaled * red_std / 255,\n",
    "            green_scaled * green_std / 255,\n",
    "            blue_scaled * blue_std / 255\n",
    "        ))\n",
    "    return str(dominant_colors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Helper functions </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Averages a list\n",
    "def average(l):\n",
    "    return sum(l) / len(l)\n",
    "\n",
    "# Makes a list of unique values from a list\n",
    "def unique(list1):\n",
    "    # Init null list\n",
    "    unique_list = []\n",
    "\n",
    "    for x in list1:\n",
    "        if x not in unique_list:\n",
    "            unique_list.append(x)\n",
    "            #print(x)\n",
    "    return unique_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Collecting visual features </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adds values for each picture to a list so they can be later averaged and \n",
    "# made into a dataframe. \n",
    "def get_features(image_folder, movie_id):\n",
    "    movie_dict = {}\n",
    "    df = pd.DataFrame()\n",
    "    saturation_list = []\n",
    "    brightness_list = []\n",
    "    entropy_list = []\n",
    "    sharpness_list = []\n",
    "    contrast_list = []\n",
    "    colorfulness_list = []\n",
    "    dominant_color_list = []\n",
    "    frame_list = []\n",
    "\n",
    "    for i in range(len(image_folder)):\n",
    "        #try:\n",
    "            img = cv2.imread(os.path.join(folder_path, image_folder[i]))\n",
    "            frame_brightness = get_brightness(img)\n",
    "            frame_saturation = get_saturation(img)\n",
    "            frame_entropy = get_entropy(img)\n",
    "            frame_sharpness = get_sharpness(img)\n",
    "            frame_contrast = get_contrast(img)\n",
    "            frame_colorfulness = get_colorfulness(img)\n",
    "            frame_domcolor = get_dominant_color(img)\n",
    "\n",
    "            saturation_list.append(frame_saturation)\n",
    "            brightness_list.append(frame_brightness)\n",
    "            entropy_list.append(frame_entropy)\n",
    "            sharpness_list.append(frame_sharpness)\n",
    "            contrast_list.append(frame_contrast)\n",
    "            colorfulness_list.append(frame_colorfulness)\n",
    "            dominant_color_list.append(frame_domcolor)\n",
    "            frame_list.append(image_folder[i][:-4])\n",
    "        #except Exception:\n",
    "           # print(\"Failure at frame_nr:\", i)\n",
    "\n",
    "    # Create movie dictionary\n",
    "    movie_dict = {\n",
    "            'saturation': saturation_list,\n",
    "            'brightness': brightness_list, \n",
    "            'entropy': entropy_list, \n",
    "            'sharpness': sharpness_list, \n",
    "            'contrast': contrast_list,\n",
    "            'frame_nr': frame_list,\n",
    "            'colorfulness': colorfulness_list,\n",
    "            'dom_col': dominant_color_list,\n",
    "            'movie_id': movie_id\n",
    "            }\n",
    "\n",
    "    df = pd.DataFrame(movie_dict)\n",
    "    df['frame_nr'] = pd.to_numeric(df['frame_nr'], downcast='integer')\n",
    "    #df = df.set_index('frame_nr')\n",
    "    df = df.sort_values(by = ['frame_nr', 'movie_id'], ascending=[True, True])\n",
    "    return df\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function to extract visual features from the movies\n",
    "if __name__ == \"__main__\":\n",
    "    movie_df = pd.DataFrame()\n",
    "    trailers = './movie_keyframes/movie_trailers/tiny_Test/'\n",
    "    trailers_read = os.listdir(trailers)\n",
    "    #print(trailers_read)\n",
    "    \n",
    "    for x in trailers_read:\n",
    "        folder_path = os.path.join(trailers,x)\n",
    "        img_folder = os.listdir(folder_path)\n",
    "        \n",
    "        movie_id = x #path.replace('./movie_keyframes/trailers/', '').replace('/','')\n",
    "        feature_dict = get_features(img_folder, movie_id)\n",
    "        movie_df = movie_df.append(feature_dict)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>saturation</th>\n",
       "      <th>brightness</th>\n",
       "      <th>entropy</th>\n",
       "      <th>sharpness</th>\n",
       "      <th>contrast</th>\n",
       "      <th>frame_nr</th>\n",
       "      <th>colorfulness</th>\n",
       "      <th>dom_col</th>\n",
       "      <th>movie_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.580431</td>\n",
       "      <td>0.136885</td>\n",
       "      <td>50.896806</td>\n",
       "      <td>11.475877</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[(0.0004702694753756598, 0.0004702694753756598...</td>\n",
       "      <td>tt0105690.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>21.252817</td>\n",
       "      <td>26.976065</td>\n",
       "      <td>3.718764</td>\n",
       "      <td>257.117550</td>\n",
       "      <td>25.342720</td>\n",
       "      <td>48</td>\n",
       "      <td>9.218765</td>\n",
       "      <td>[(0.3167931935264684, 0.31380663787928753, 0.3...</td>\n",
       "      <td>tt0105690.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.168827</td>\n",
       "      <td>30.356037</td>\n",
       "      <td>4.289692</td>\n",
       "      <td>262.512469</td>\n",
       "      <td>28.535563</td>\n",
       "      <td>101</td>\n",
       "      <td>5.582645</td>\n",
       "      <td>[(-0.3942233310747467, -0.3779269332396935, -0...</td>\n",
       "      <td>tt0105690.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.898330</td>\n",
       "      <td>33.539167</td>\n",
       "      <td>4.460732</td>\n",
       "      <td>343.555235</td>\n",
       "      <td>33.616063</td>\n",
       "      <td>161</td>\n",
       "      <td>7.385653</td>\n",
       "      <td>[(0.3774313898176223, 0.3600278803783049, 0.36...</td>\n",
       "      <td>tt0105690.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>28.654527</td>\n",
       "      <td>25.723623</td>\n",
       "      <td>4.478536</td>\n",
       "      <td>737.720709</td>\n",
       "      <td>44.284965</td>\n",
       "      <td>211</td>\n",
       "      <td>18.353962</td>\n",
       "      <td>[(-0.3046666558485848, -0.30827596790080875, -...</td>\n",
       "      <td>tt0105690.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>37.997600</td>\n",
       "      <td>7.120933</td>\n",
       "      <td>1.298146</td>\n",
       "      <td>69.632614</td>\n",
       "      <td>18.998112</td>\n",
       "      <td>2328</td>\n",
       "      <td>6.315043</td>\n",
       "      <td>[(0.010385437699950364, 0.014726938622916694, ...</td>\n",
       "      <td>tt0105690.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>81.566552</td>\n",
       "      <td>11.708530</td>\n",
       "      <td>1.213764</td>\n",
       "      <td>357.462778</td>\n",
       "      <td>55.147209</td>\n",
       "      <td>2388</td>\n",
       "      <td>24.829325</td>\n",
       "      <td>[(-0.2506942429198065, -0.17393846639905988, -...</td>\n",
       "      <td>tt0105690.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>83.487963</td>\n",
       "      <td>11.127115</td>\n",
       "      <td>1.113452</td>\n",
       "      <td>417.167207</td>\n",
       "      <td>55.066666</td>\n",
       "      <td>2448</td>\n",
       "      <td>24.058931</td>\n",
       "      <td>[(0.3656850434461838, 0.06878865721582993, 0.2...</td>\n",
       "      <td>tt0105690.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>15.129509</td>\n",
       "      <td>26.756648</td>\n",
       "      <td>3.281468</td>\n",
       "      <td>6068.359892</td>\n",
       "      <td>87.200338</td>\n",
       "      <td>2508</td>\n",
       "      <td>6.597199</td>\n",
       "      <td>[(0.2964485565674506, 0.28355247327447164, 0.3...</td>\n",
       "      <td>tt0105690.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>13.330183</td>\n",
       "      <td>6.669677</td>\n",
       "      <td>2.732231</td>\n",
       "      <td>866.207886</td>\n",
       "      <td>25.653860</td>\n",
       "      <td>2568</td>\n",
       "      <td>2.586324</td>\n",
       "      <td>[(0.2573306326598045, 0.25646869985958043, 0.2...</td>\n",
       "      <td>tt0105690.mp4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    saturation  brightness   entropy    sharpness   contrast  frame_nr  \\\n",
       "2     0.000000    0.580431  0.136885    50.896806  11.475877         0   \n",
       "55   21.252817   26.976065  3.718764   257.117550  25.342720        48   \n",
       "4     7.168827   30.356037  4.289692   262.512469  28.535563       101   \n",
       "0     8.898330   33.539167  4.460732   343.555235  33.616063       161   \n",
       "36   28.654527   25.723623  4.478536   737.720709  44.284965       211   \n",
       "..         ...         ...       ...          ...        ...       ...   \n",
       "43   37.997600    7.120933  1.298146    69.632614  18.998112      2328   \n",
       "44   81.566552   11.708530  1.213764   357.462778  55.147209      2388   \n",
       "45   83.487963   11.127115  1.113452   417.167207  55.066666      2448   \n",
       "47   15.129509   26.756648  3.281468  6068.359892  87.200338      2508   \n",
       "48   13.330183    6.669677  2.732231   866.207886  25.653860      2568   \n",
       "\n",
       "    colorfulness                                            dom_col  \\\n",
       "2       0.000000  [(0.0004702694753756598, 0.0004702694753756598...   \n",
       "55      9.218765  [(0.3167931935264684, 0.31380663787928753, 0.3...   \n",
       "4       5.582645  [(-0.3942233310747467, -0.3779269332396935, -0...   \n",
       "0       7.385653  [(0.3774313898176223, 0.3600278803783049, 0.36...   \n",
       "36     18.353962  [(-0.3046666558485848, -0.30827596790080875, -...   \n",
       "..           ...                                                ...   \n",
       "43      6.315043  [(0.010385437699950364, 0.014726938622916694, ...   \n",
       "44     24.829325  [(-0.2506942429198065, -0.17393846639905988, -...   \n",
       "45     24.058931  [(0.3656850434461838, 0.06878865721582993, 0.2...   \n",
       "47      6.597199  [(0.2964485565674506, 0.28355247327447164, 0.3...   \n",
       "48      2.586324  [(0.2573306326598045, 0.25646869985958043, 0.2...   \n",
       "\n",
       "         movie_id  \n",
       "2   tt0105690.mp4  \n",
       "55  tt0105690.mp4  \n",
       "4   tt0105690.mp4  \n",
       "0   tt0105690.mp4  \n",
       "36  tt0105690.mp4  \n",
       "..            ...  \n",
       "43  tt0105690.mp4  \n",
       "44  tt0105690.mp4  \n",
       "45  tt0105690.mp4  \n",
       "47  tt0105690.mp4  \n",
       "48  tt0105690.mp4  \n",
       "\n",
       "[67 rows x 9 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#movie_df['frame_nr'] = pd.to_numeric(movie_df['frame_nr'], downcast='integer')\n",
    "#movie_df = movie_df.sort_values(by=['frame_nr'], axis=0, ascending=True)\n",
    "#movie_df.dtypes\n",
    "#movie_df.to_csv('output.csv')\n",
    "movie_df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Natural log and transform all numbers to positive numbers\n",
    "movie_df['saturation'] = np.log(movie_df['saturation'] + 1 - min(movie_df['saturation']))\n",
    "movie_df['brightness'] = np.log(movie_df['brightness'] + 1 - min(movie_df['brightness']))\n",
    "movie_df['entropy'] = np.log(movie_df['entropy'] + 1 - min(movie_df['entropy']))\n",
    "movie_df['sharpness'] = np.log(movie_df['sharpness'] + 1 - min(movie_df['sharpness']))\n",
    "movie_df['contrast'] = np.log(movie_df['contrast'] + 1 - min(movie_df['contrast']))\n",
    "\n",
    "movie_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Condensing all features to single rows per movie </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deprecated function  \n",
    "def polynomial_regression(id, df):\n",
    "    temp_df = df\n",
    "    temp_df['frame_nr'] = pd.to_numeric(temp_df['frame_nr'], downcast='integer')\n",
    "    temp_df = temp_df.sort_values(by=['frame_nr'], axis=0, ascending=True)\n",
    "\n",
    "\n",
    "    frame_nr = temp_df['frame_nr'][temp_df['movie_id'] == id]\n",
    "    saturation = temp_df['saturation'][temp_df['movie_id'] == id]\n",
    "    brightness = temp_df['brightness'][temp_df['movie_id'] == id]\n",
    "    entropy = temp_df['entropy'][temp_df['movie_id'] == id]\n",
    "    sharpness = temp_df['sharpness'][temp_df['movie_id'] == id]\n",
    "    contrast = temp_df['contrast'][temp_df['movie_id'] == id]\n",
    "\n",
    "\n",
    "    saturation_model_1st = np.poly1d(np.polyfit(frame_nr, saturation, 1))\n",
    "    brightness_model_1st = np.poly1d(np.polyfit(frame_nr, brightness, 1))\n",
    "    entropy_model_1st = np.poly1d(np.polyfit(frame_nr, entropy, 1))\n",
    "    sharpness_model_1st = np.poly1d(np.polyfit(frame_nr, sharpness, 1))\n",
    "    contrast_model_1st = np.poly1d(np.polyfit(frame_nr, contrast, 1))\n",
    "\n",
    "\n",
    "    saturation_model_2nd = np.poly1d(np.polyfit(frame_nr, saturation, 2))\n",
    "    brightness_model_2nd = np.poly1d(np.polyfit(frame_nr, brightness, 2))\n",
    "    entropy_model_2nd = np.poly1d(np.polyfit(frame_nr, entropy, 2))\n",
    "    sharpness_model_2nd = np.poly1d(np.polyfit(frame_nr, sharpness, 2))\n",
    "    contrast_model_2nd= np.poly1d(np.polyfit(frame_nr, contrast, 2))\n",
    "\n",
    "\n",
    "    \n",
    "    polynomial_dict = {\n",
    "        'saturation_model_1st': saturation_model_1st, \n",
    "        'brightness_model_1st': brightness_model_1st,\n",
    "        'entropy_model_1st': entropy_model_1st,\n",
    "        'sharpness_model_1st': sharpness_model_1st,\n",
    "        'contrast_model_1st': contrast_model_1st,\n",
    "        'saturation_model_2nd': saturation_model_2nd,\n",
    "        'brightness_model_2nd': brightness_model_2nd,\n",
    "        'entropy_model_2nd': entropy_model_2nd,\n",
    "        'sharpness_model_2nd': sharpness_model_2nd,\n",
    "        'contrast_model_2nd': contrast_model_2nd\n",
    "    }\n",
    "\n",
    "    print(polynomial_dict)\n",
    "    #return pd.DataFrame(polynomial_dict)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "#polynomial_regression('2', movie_df)\n",
    "#poly_test.head()\n",
    "#plt.scatter(frame_nr, brightness)\n",
    "#plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Polynomial regression on the movies\n",
    "# Currently all values are formatted as strings (might be changed later)\n",
    "def polynomial_regression_alt(df, id):\n",
    "    temp_df = df\n",
    "    temp_df['frame_nr'] = pd.to_numeric(temp_df['frame_nr'], downcast='integer')\n",
    "    temp_df = temp_df.sort_values(by=['frame_nr'], axis=0, ascending=True)\n",
    "    output = pd.DataFrame()\n",
    "\n",
    "\n",
    "    frame_nr = temp_df['frame_nr'][temp_df['movie_id'] == id]\n",
    "    saturation = temp_df['saturation'][temp_df['movie_id'] == id]\n",
    "    brightness = temp_df['brightness'][temp_df['movie_id'] == id]\n",
    "    entropy = temp_df['entropy'][temp_df['movie_id'] == id]\n",
    "    sharpness = temp_df['sharpness'][temp_df['movie_id'] == id]\n",
    "    contrast = temp_df['contrast'][temp_df['movie_id'] == id]\n",
    "\n",
    "    saturation_model_1st = str(np.poly1d(np.polyfit(frame_nr, saturation, 1)))\n",
    "    brightness_model_1st = str(np.poly1d(np.polyfit(frame_nr, brightness, 1)))\n",
    "    entropy_model_1st = str(np.poly1d(np.polyfit(frame_nr, entropy, 1)))\n",
    "    sharpness_model_1st = str(np.poly1d(np.polyfit(frame_nr, sharpness, 1)))\n",
    "    contrast_model_1st = str(np.poly1d(np.polyfit(frame_nr, contrast, 1)))\n",
    "\n",
    "    saturation_model_2nd = str(np.poly1d(np.polyfit(frame_nr, saturation, 2)))\n",
    "    brightness_model_2nd = str(np.poly1d(np.polyfit(frame_nr, brightness, 2)))\n",
    "    entropy_model_2nd = str(np.poly1d(np.polyfit(frame_nr, entropy, 2)))\n",
    "    sharpness_model_2nd = str(np.poly1d(np.polyfit(frame_nr, sharpness, 2)))\n",
    "    contrast_model_2nd = str(np.poly1d(np.polyfit(frame_nr, contrast, 2)))\n",
    "\n",
    "\n",
    "    \n",
    "    polynomial_dict = {\n",
    "        'movie_id': str(id),\n",
    "        'saturation_model_1st': saturation_model_1st, \n",
    "        'brightness_model_1st': brightness_model_1st,\n",
    "        'entropy_model_1st': entropy_model_1st,\n",
    "        'sharpness_model_1st': sharpness_model_1st,\n",
    "        'contrast_model_1st': contrast_model_1st,\n",
    "        'saturation_model_2nd': saturation_model_2nd,\n",
    "        'brightness_model_2nd': brightness_model_2nd,\n",
    "        'entropy_model_2nd': entropy_model_2nd,\n",
    "        'sharpness_model_2nd': sharpness_model_2nd,\n",
    "        'contrast_model_2nd': contrast_model_2nd\n",
    "    }\n",
    "\n",
    "    output = output.append(polynomial_dict, ignore_index=True)\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New dataframe condensing each movie into a single row \n",
    "def movie_matrix(df, id):\n",
    "    matrix = pd.DataFrame()\n",
    "\n",
    "    avg_brightness = average(df['brightness'][df['movie_id'] == id])\n",
    "    avg_saturation = average(df['saturation'][df['movie_id'] == id])\n",
    "    avg_entropy = average(df['entropy'][df['movie_id'] == id])\n",
    "    avg_sharpness = average(df['sharpness'][df['movie_id'] == id])\n",
    "    avg_contrast = average(df['contrast'][df['movie_id'] == id])\n",
    "\n",
    "\n",
    "    stdev_brightness = statistics.stdev((df['brightness'][df['movie_id'] == id]))\n",
    "    stdev_saturation = statistics.stdev((df['saturation'][df['movie_id'] == id]))\n",
    "    stdev_entropy = statistics.stdev((df['entropy'][df['movie_id'] == id]))\n",
    "    stdev_sharpness = statistics.stdev((df['sharpness'][df['movie_id'] == id]))\n",
    "    stdev_contrast = statistics.stdev((df['contrast'][df['movie_id'] == id]))\n",
    "\n",
    "    mean_brightness = statistics.mean((df['brightness'][df['movie_id'] == id]))\n",
    "    mean_saturation = statistics.mean((df['saturation'][df['movie_id'] == id]))\n",
    "    mean_entropy = statistics.mean((df['entropy'][df['movie_id'] == id]))\n",
    "    mean_sharpness = statistics.mean((df['sharpness'][df['movie_id'] == id]))\n",
    "    mean_contrast = statistics.mean((df['contrast'][df['movie_id'] == id]))\n",
    "\n",
    "\n",
    "    matrix_dict = {\n",
    "        'movie_id': str(id),\n",
    "        'avg_brightness': avg_brightness,\n",
    "        'avg_saturation': avg_saturation,\n",
    "        'avg_entropy': avg_entropy,\n",
    "        'avg_sharpness': avg_sharpness,\n",
    "        'avg_contrast': avg_contrast,\n",
    "        'stdev_brightness': stdev_brightness,\n",
    "        'stdev_saturation': stdev_saturation,\n",
    "        'stdev_entropy': stdev_entropy,\n",
    "        'stdev_sharpness': stdev_sharpness,\n",
    "        'stdev_contrast': stdev_contrast,\n",
    "        'mean_brightness': mean_brightness,\n",
    "        'mean_saturation': mean_saturation,\n",
    "        'mean_entropy': mean_entropy,\n",
    "        'mean_sharpness': mean_sharpness,\n",
    "        'mean_contrast': mean_contrast\n",
    "    }\n",
    "\n",
    "    matrix = matrix.append(matrix_dict, ignore_index = True)\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test cell \n",
    "numbers = [1,1,2,3,4,5,5,5,5,5,6]\n",
    "unique_numbers = unique(numbers)\n",
    "print(unique_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Makes sure there is no overlap between movie_id's \n",
    "unique_movie_id_list = unique(movie_df['movie_id'])\n",
    "print(unique_movie_id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Makes two dataframes\n",
    "# One containing polynomials, and one containing averages etc. \n",
    "poly_df = pd.DataFrame()\n",
    "matrix_df = pd.DataFrame()\n",
    "\n",
    "for x in unique_movie_id_list:\n",
    "    poly_df = poly_df.append(polynomial_regression_alt(movie_df, x))\n",
    "    \n",
    "    matrix_df = matrix_df.append(movie_matrix(movie_df, x))\n",
    "final_matrix = pd.merge(poly_df, matrix_df, on = 'movie_id')\n",
    "final_matrix.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantile_normalize(df):\n",
    "    \"\"\"\n",
    "    input: dataframe with numerical columns\n",
    "    output: dataframe with quantile normalized values\n",
    "    \"\"\"\n",
    "    df_sorted = pd.DataFrame(np.sort(df.values,\n",
    "                                     axis=0), \n",
    "                             index=df.index, \n",
    "                             columns=df.columns)\n",
    "    df_mean = df_sorted.mean(axis=1)\n",
    "    df_mean.index = np.arange(1, len(df_mean) + 1)\n",
    "    return df.rank(method=\"min\").stack().astype(int).map(df_mean).unstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Cosine similarity </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cosine similarity between two rows\n",
    "def compute_cos_sim(array1, array2):\n",
    "    return 1 - spatial.distance.cosine(array1, array2)\n",
    "\n",
    "# Cosine similarity between all rows\n",
    "def compute_cos_sim_all(my_array):\n",
    "    n_rows = my_array.shape[0]\n",
    "    cos_sim_array = np.zeros((n_rows,n_rows))\n",
    "    for row1 in range(n_rows):\n",
    "        for row2 in range(n_rows):\n",
    "            cos_sim_array[row1,row2] = \\\n",
    "            compute_cos_sim(my_array[row1, :],\\\n",
    "                            my_array[row2, :])\n",
    "    return cos_sim_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drops the movie_id value. Can be retrieved with iloc \n",
    "matrix_no_id = matrix_df.drop('movie_id', 1)\n",
    "#matrix_no_id = quantile_normalize(matrix_no_id)\n",
    "# Converts dataframe to numpy array\n",
    "matrix_no_id_array = matrix_no_id.to_numpy()\n",
    "# Calculates cosine similarity between the movies \n",
    "cos_sim_values = compute_cos_sim_all(matrix_no_id_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draws heatmap of the similarities between movies \n",
    "fig = plt.figure()\n",
    "ax = plt.imshow(cos_sim_values, cmap='hot')\n",
    "cbar = fig.colorbar(ax)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(movie_list.iloc[28])\n",
    "print(movie_list.iloc[18])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test cell for implementing polynomials in heatmap \n",
    "# Drops the movie_id value. The movie_id be retrieved with iloc \n",
    "matrix_no_id = final_matrix.drop('movie_id', 1)\n",
    "# Converts dataframe to numpy array\n",
    "matrix_no_id_array = matrix_no_id.to_numpy()\n",
    "# Calculates cosine similarity between the movies \n",
    "#cos_sim_values = compute_cos_sim_all(matrix_no_id_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Data analytics</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardising movie data\n",
    "standardised_movie_data = StandardScaler().fit_transform(movie_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elbow method\n",
    "distortions = []\n",
    "for i in range(1, 11):\n",
    "    km = KMeans(n_clusters = i, init='k-means++', \n",
    "                n_init=10, max_iter=300, \n",
    "                random_state=0)\n",
    "    km.fit(matrix_no_id)\n",
    "    distortions.append(km.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KMeans clustering using output from Elbow method\n",
    "km_plus = KMeans(n_clusters = 8, init='k-means++', \n",
    "                n_init=10, max_iter=300, \n",
    "                random_state=0)\n",
    "movie_fit = km_plus.fit_predict(movie_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MiniBatchSparcePCA \n",
    "transformer = MiniBatchSparsePCA(n_components=5, batch_size=50,\n",
    "                                 random_state=0)\n",
    "movie_mini_pca_fit = MiniBatchSparsePCA.fit_transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA \n",
    "standardised_movie_data = StandardScaler().fit_transform(movie_df)\n",
    "pca = PCA(n_components = 4)\n",
    "movie_pca = pca.fit_transform(standardised_movie_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> TO DO </h1>\n",
    "<p> \n",
    "    <ul>\n",
    "        <li>Clustering</li>\n",
    "        <li>Add deep visual features (object / action detection)</li>\n",
    "        <li>Normalize all features, using log or </li>\n",
    "        <li>Recommendation libraries: librec (DeepFM, FM, Wide & Deep, Youtube - recommendation) </li>\n",
    "        <li> Train-test split (5 fold cross validation) </li>\n",
    "        <li> precision > RMSE </li>\n",
    "        <li> Correlation analysis movies ( pearson correlation) </li>\n",
    "        <li> histogram difference between features </li>\n",
    "        <li> more standard deviation == good!!! </li>\n",
    "        <li> low cost == no ratings, high cost == more ratings </li>\n",
    "        <li> high correlation, remove one </li>\n",
    "        <li> random forrest, PCA </li>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f6991c196b23c1d885f0f9e835ae9d746441284eb49bc25aa917a366e6a0b33d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
